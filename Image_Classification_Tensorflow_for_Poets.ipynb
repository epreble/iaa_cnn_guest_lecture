{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sectionTop'></a>\n",
    "# Image Classification with Tensorflow/Inception\n",
    "\n",
    "[1. Installation (Mac)](#section1)<br>\n",
    "&nbsp;&nbsp;&nbsp;A. Tensorflow<br>\n",
    "&nbsp;&nbsp;&nbsp;B. Docker Container<br>\n",
    "&nbsp;&nbsp;&nbsp;C. Inception v3<br>\n",
    "[2. Prep of images/data for tensorflow](#section2)<br>\n",
    "&nbsp;&nbsp;&nbsp;A. Flowers Data (Google \"Tensorflow for Poets\" Demo)<br>\n",
    "[3. Retraining the model](#section3)<br>\n",
    "[4. Validation code for classification model (label_image.py)](#section4)<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 1. Installation (Mac)\n",
    "I use Miniconda for my python environments. These commands are done from command line (Mac Terminal).<br>\n",
    "NOTE:\n",
    "- Donâ€™t change the order of these commands! (There are some weird pip bugs right now)\n",
    "- You must use Python 3.6 (tensorflow does not work on python 3.7 as of 10/6/2018)\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "conda create -n iaa python=3.6\n",
    "<br>source activate iaa\n",
    "<br>pip install --upgrade pip\n",
    "<br>pip install --upgrade \"tensorflow==1.7.*\"\n",
    "</div>\n",
    "\n",
    "Validate Install - Start python shell, then run the below code snippet. Prints \"Hello, TensorFlow!\" if working ok\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "python\n",
    "<br>\n",
    "<br>import tensorflow as tf\n",
    "<br>hello = tf.constant('Hello, TensorFlow!')\n",
    "<br>sess = tf.Session()\n",
    "<br>print(sess.run(hello))\n",
    "<br>exit()\n",
    "</div>\n",
    "\n",
    "Copy Inception v3 architecture and pre-trained library\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "git clone https://github.com/googlecodelabs/tensorflow-for-poets-2\n",
    "<br>cd tensorflow-for-poets-2\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 2. Prep of images/data for tensorflow\n",
    "\n",
    "Tensorflow appears to prefer JPGs. PNG can supposedly work (as it does in Tensorbox demo), but I haven't gotten it working for this basic classification example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flowers Data (Google \"Tensorflow for Poets\" Demo):\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "curl http://download.tensorflow.org/example_images/flower_photos.tgz \\\n",
    "<br>tar xz -C tf_files\n",
    "<br>ls tf_files/flower_photos\n",
    "</div>\n",
    "\n",
    "Should list 5 directories, which have ~3600 images in total:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "daisy/\n",
    "<br>dandelion/\n",
    "<br>roses/\n",
    "<br>sunflowers/\n",
    "<br>tulips/\n",
    "<br>LICENSE.txt\n",
    "</div>\n",
    "\n",
    "Move a few images of each flower out of training location to use for testing later:\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "mkdir test_images\n",
    "<br>mkdir test_images/flower_photos\n",
    "<br>mv ./tf_files/flower_photos/roses/102501987_3cdb8e5394_n.jpg ./test_images/flower_photos/rose1.jpg\n",
    "<br>mv ./tf_files/flower_photos/roses/6231418894_7946a7712b_n.jpg ./test_images/flower_photos/rose2.jpg\n",
    "<br>mv ./tf_files/flower_photos/roses/21522100663_455b77a90c_n.jpg ./test_images/flower_photos/rose3.jpg\n",
    "<br>mv ./tf_files/flower_photos/daisy/5547758_eea9edfd54_n.jpg ./test_images/flower_photos/daisy1.jpg\n",
    "<br>mv ./tf_files/flower_photos/daisy/2713919471_301fcc941f.jpg ./test_images/flower_photos/daisy2.jpg\n",
    "<br>mv ./tf_files/flower_photos/daisy/7630520686_e3a61ac763.jpg ./test_images/flower_photos/daisy3.jpg\n",
    "<br>mv ./tf_files/flower_photos/dandelion/8475758_4c861ab268_m.jpg ./test_images/flower_photos/dandelion1.jpg\n",
    "<br>mv ./tf_files/flower_photos/dandelion/4632761610_768360d425.jpg ./test_images/flower_photos/dandelion2.jpg\n",
    "<br>mv ./tf_files/flower_photos/dandelion/15644450971_6a28298454_n.jpg ./test_images/flower_photos/dandelion3.jpg\n",
    "<br>mv ./tf_files/flower_photos/sunflowers/27465811_9477c9d044.jpg ./test_images/flower_photos/sunflowers1.jpg\n",
    "<br>mv ./tf_files/flower_photos/sunflowers/5020805135_1219d7523d.jpg ./test_images/flower_photos/sunflowers2.jpg\n",
    "<br>mv ./tf_files/flower_photos/sunflowers/9056495873_66e351b17c_n.jpg ./test_images/flower_photos/sunflowers3.jpg\n",
    "<br>mv ./tf_files/flower_photos/tulips/11746367_d23a35b085_n.jpg ./test_images/flower_photos/tulips1.jpg\n",
    "<br>mv ./tf_files/flower_photos/tulips/5674695558_61397a1584.jpg ./test_images/flower_photos/tulips2.jpg\n",
    "<br>mv ./tf_files/flower_photos/tulips/13923539227_bdab038dc8.jpg ./test_images/flower_photos/tulips3.jpg\n",
    "</div>\n",
    "\n",
    "<center>Example Rose Image</center> | <center>Example Tulip Image</center>\n",
    "- | - \n",
    "<img src=\"./test_images/flower_photos/rose1.jpg\" alt=\"Rose\" style=\"width: 400px;\"/> | <img src=\"./test_images/flower_photos/tulips1.jpg\" alt=\"Tulip\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 3. Retraining the Model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In terminal window, startup tensorflow dashboard to monitor the training process\n",
    "(if using miniconda environments as specified above, be sure \"iaa\" environment is running. \"source activate iaa\"\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "IMAGE_SIZE=224\n",
    "<br>ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\"\n",
    "<br>tensorboard --logdir tf_files/training_summaries &\n",
    "</div>\n",
    "\n",
    "###### In another terminal window, run the retraining scripts\n",
    "(if using miniconda environments as specified above, be sure \"iaa\" environment is running. \"source activate iaa\"\n",
    "<br>Run the python retraining script help, confirms that the retrain.py is functioning ok\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "python -m scripts.retrain -h\n",
    "</div>\n",
    "\n",
    "<br>This script handles 3 things:\n",
    "- Download model architecture (only happens once for that model)\n",
    "- Create bottleneck files for each training image (only happens the first time an image is trained)\n",
    "    - On Mac laptop, ~4 mins per 1000 images (~300x300 pixel)\n",
    "    - On Mac laptop, ~6 mins per 1000 images (~4096x2160 pixel)\n",
    "- Retrain model (n training steps executed, 4000 is default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Flowers Data (Google \"Tensorflow for Poets\" Demo):\n",
    "ImageNet can be retrained using the Inception_v3 architecture on the Flowers dataset with the below command\n",
    "<br> 15 mins to make bottlenecks the first time\n",
    "<br> 3 mins to train 500 steps (claims 89.7% accuracy)\n",
    "<br>21 mins to train 4000 steps (claims 91.1% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/inception_v3 \\\n",
    "  --output_graph=tf_files/output/flowers_500_graph.pb \\\n",
    "  --output_labels=tf_files/output/flowers_500_labels.txt \\\n",
    "  --architecture=inception_v3 \\\n",
    "  --image_dir=tf_files/flower_photos```\n",
    "  \n",
    "<br>Can train longer, say 4000 steps, with:\n",
    "\n",
    "```python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=4000 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/inception_v3 \\\n",
    "  --output_graph=tf_files/output/flowers_4000_graph.pb \\\n",
    "  --output_labels=tf_files/output/flowers_4000_labels.txt \\\n",
    "  --architecture=inception_v3 \\\n",
    "  --image_dir=tf_files/flower_photos```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a><span style=\"float:right\">[Back to Top](#sectionTop)</span>\n",
    "# 4. Validation code for classification model\n",
    "\n",
    "As of 9/23/17, there is a bug in label_image.py. Change the following lines:\n",
    "\n",
    "```\n",
    "# Change from this:\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "input_mean = 128\n",
    "input_std = 128\n",
    "input_layer = \"input\"\n",
    "\n",
    "# Change to this:\n",
    "input_height = 299\n",
    "input_width = 299\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "input_layer = \"Mul\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Flowers Data (Google \"Tensorflow for Poets\" Demo):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model reported 91.1% accuracy after 4000 step training.\n",
    "Some actual results below (14/15 correct):\n",
    "\n",
    "```python -m scripts.label_image \\\n",
    "    --graph=tf_files/output/flowers_4000_graph.pb  \\\n",
    "    --labels=tf_files/output/flowers_4000_labels.txt  \\\n",
    "    --image=test_images/flower_photos/rose1.jpg```\n",
    "\n",
    "<center></center> | <center></center> | <center></center>\n",
    "- | - | -\n",
    "<center>**Rose 1<br>roses 0.999549**<br>tulips 0.000405927<br>sunflowers 3.60402e-05<br>daisy 9.16548e-06<br>dandelion 1.75581e-07</center> | <center>**Rose 2<br>roses 0.968867**<br>tulips 0.027235<br>sunflowers 0.00199636<br>daisy 0.000950742<br>dandelion 0.000950667</center> | <center>**Rose 3<br>roses 0.871816**<br>tulips 0.126929<br>sunflowers 0.00119743<br>dandelion 4.76507e-05<br>daisy 1.0666e-05</center>\n",
    "<img src=\"./images/test/rose1.jpg\"/> | <img src=\"./images/test/rose2.jpg\"/> | <img src=\"./images/test/rose3.jpg\"/>\n",
    "||\n",
    "||\n",
    "||\n",
    "||\n",
    "<center>**Tulip 1<br>tulips 0.923023**<br>roses 0.0622453<br>dandelion 0.00861938<br>daisy 0.00473263<br>sunflowers 0.00137952</center> | <center>**Tulip 2<br>tulips 0.892067**<br>sunflowers 0.0802674<br>daisy 0.0132293<br>dandelion 0.00992827<br>roses 0.00450842</center> | <center>**Tulip 3<br>tulips 0.882232**<br>dandelion 0.0571973<br>sunflowers 0.0330509<br>roses 0.0170892<br>daisy 0.010431</center>\n",
    "<img src=\"./images/test/tulips1.jpg\"/> | <img src=\"./images/test/tulips2.jpg\"/> | <img src=\"./images/test/tulips3.jpg\"/>\n",
    "||\n",
    "||\n",
    "||\n",
    "||\n",
    "<center>**Dandelion 1<br>dandelion 0.560596**<br>sunflowers 0.394746<br>daisy 0.0403786<br>tulips 0.00343286<br>roses 0.000846216</center> | <center>**Dandelion 2<br>dandelion 0.999977**<br>sunflowers 9.7611e-06<br>tulips 5.85115e-06<br>roses 4.09581e-06<br>daisy 3.87133e-06</center> | <center>**Dandelion 3**<br><font color=\"FF0000\">**sunflowers 0.544294**</font><br>dandelion 0.399705<br>tulips 0.0297771<br>daisy 0.0259137<br>roses 0.000310016</center>\n",
    "<img src=\"./images/test/dandelion1.jpg\"/> | <img src=\"./images/test/dandelion2.jpg\"/> | <img src=\"./images/test/dandelion3.jpg\"/>\n",
    "||\n",
    "||\n",
    "||\n",
    "||\n",
    "<center>**Daisy 1<br>daisy 0.985345**<br>dandelion 0.00887047<br>sunflowers 0.00449815<br>tulips 0.00098446<br>roses 0.00030153</center> | <center>**Daisy 2<br>daisy 0.997346**<br>sunflowers 0.00226963<br>dandelion 0.000252017<br>roses 8.0504e-05<br>tulips 5.18256e-05</center> | <center>**Daisy 3<br>daisy 0.995164**<br>sunflowers 0.00406516<br>dandelion 0.000363425<br>tulips 0.000302943<br>roses 0.000104804</center>\n",
    "<img src=\"./images/test/daisy1.jpg\"/> | <img src=\"./images/test/daisy2.jpg\"/> | <img src=\"./images/test/daisy3.jpg\"/>\n",
    "||\n",
    "||\n",
    "||\n",
    "||\n",
    "<center>**Sunflower 1<br>sunflowers 0.963783**<br>dandelion 0.0171869<br>tulips 0.00798338<br>daisy 0.00797936<br>roses 0.00306722</center> | <center>**Sunflower 2<br>sunflowers 0.971356**<br>dandelion 0.014657<br>daisy 0.0103836<br>tulips 0.00298796<br>roses 0.000615895</center> | <center>**Sunflower 3<br>sunflowers 0.780127**<br>tulips 0.143532<br>dandelion 0.0735062<br>roses 0.00280192<br>daisy 3.27696e-05</center>\n",
    "<img src=\"./images/test/sunflowers1.jpg\"/> | <img src=\"./images/test/sunflowers2.jpg\"/> | <img src=\"./images/test/sunflowers3.jpg\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
